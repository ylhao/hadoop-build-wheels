## 单节点伪分布式

安装配置过程直接参考官方教程即可，连接在最后给出。


```
# 格式化文件系统
bin/hdfs namenode -format

# 启动 namenode 守护进程 和 datanode 的守护进程
 sbin/start-dfs.sh

# 启动 ResourceManager 守护进程和 NodeManager 守护进程
sbin/start-yarn.sh

# 创建 user 目录
bin/hdfs dfs -mkdir /user

# 在 user 目录下创建 root 目录
bin/hdfs dfs -mkdir /user/root

# 将 etc 目录下的 hadoop 文件夹下的内容推送到 HDFS 文件系统中的 /user/root/input/ 目录下。
# 如果没有 input 目录，则会自动创建。
 bin/hdfs dfs -put etc/hadoop input

# 查看文件列表
bin/hdfs dfs -ls /user/root/input

# 删除文件夹
bin/hdfs dfs -rm -r /user/ylhao

# 跑一下官网提供的 wordcount 例子
 bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount input output

# 执行完后，执行以下命令，发现在 /user/root/ 目录下多了一个 output 文件夹
bin/hdfs dfs -ls /user/root/

# 将输出结果从 dfs 复制到本机文件系统
bin/hdfs dfs -get output output

# 查看结果
cat output/*

# 或者直接在 dfs 中查看结果
bin/hdfs dfs -cat output/*

# 结束守护进程
sbin/stop-yarn.sh
sbin/stop-dfs.sh
```
## 参考
[Hadoop: Setting up a Single Node Cluster.](https://hadoop.apache.org/docs/r2.7.5/hadoop-project-dist/hadoop-common/SingleCluster.html)
 
